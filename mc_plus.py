# mc_plus.py ì „ì²´ë¥¼ ì´ ì½”ë“œë¡œ ë®ì–´ì“°ì„¸ìš”.

import numpy as np
import pandas as pd
import jax.numpy as jnp
from jax import jit
from typing import Dict, List, Tuple

class KalmanFilter1D:
    def __init__(self, R=0.01, Q=1e-5):
        self.R = R
        self.Q = Q
        self.P = 1.0
        self.x = None
        
    def update(self, measurement):
        if self.x is None:
            self.x = measurement
            return self.x
        x_pred = self.x
        P_pred = self.P + self.Q
        K = P_pred / (P_pred + self.R)
        self.x = x_pred + K * (measurement - x_pred)
        self.P = (1 - K) * P_pred
        return self.x

class OUProcess:
    def __init__(self, window=20):
        self.window = window
    def get_z_score(self, prices):
        if len(prices) < self.window: return 0.0
        log_prices = np.log(prices[-self.window:])
        mu = np.mean(log_prices)
        sigma = np.std(log_prices)
        if sigma < 1e-9: return 0.0
        return (log_prices[-1] - mu) / sigma

class LSMModel:
    @staticmethod
    @jit
    def calculate_values(paths, entry_price, direction, leverage, discount=0.9999):
        # paths shape: (sims, steps)
        current_price = jnp.mean(paths[:, 0])
        exercise_value = (current_price - entry_price) / entry_price * direction * leverage
        
        future_prices = paths[:, 1:]
        future_pnl = (future_prices - entry_price) / entry_price * direction * leverage
        
        n_steps = future_pnl.shape[1]
        discount_factors = jnp.power(discount, jnp.arange(1, n_steps + 1))
        discounted_pnl = future_pnl * discount_factors[None, :]
        
        continuation_value = jnp.mean(jnp.sum(discounted_pnl, axis=1))
        return exercise_value, continuation_value

class LeverageOptimizer:
    def __init__(self, max_leverage=10.0, kelly_fraction=0.5):
        self.max_leverage = max_leverage
        self.kelly_fraction = kelly_fraction
        
    def calculate_optimal_leverage(self, win_rate, avg_win, avg_loss, z_score, volatility):
        if avg_loss < 1e-9: avg_loss = 1e-9
        b_ratio = avg_win / abs(avg_loss)
        kelly_pct = win_rate - ((1 - win_rate) / b_ratio)
        if kelly_pct <= 0: return 1.0
        
        safe_kelly = kelly_pct * self.kelly_fraction
        target_vol = 0.02
        vol_leverage = target_vol / (volatility + 1e-9)
        
        raw_leverage = min(safe_kelly * 10, vol_leverage)
        
        ou_penalty = 1.0
        if abs(z_score) > 1.0:
            ou_penalty = max(0.0, 1.0 - (abs(z_score) - 1.0) * 0.5)
            
        final_leverage = np.clip(raw_leverage * ou_penalty, 1.0, self.max_leverage)
        return float(round(final_leverage * 2) / 2)

class QuantDecisionEngine:
    def __init__(self):
        self.kalman = KalmanFilter1D()
        self.ou = OUProcess(window=20)
        self.lsm = LSMModel()
        
    def decide(self, mc_engine, symbol, current_price, position, historical_prices, market_data, win_probability=0.5):
        # 1. ì ˆëŒ€ ì†ì ˆ (-1.5%)
        pnl_pct = (current_price - position['entry_price']) / position['entry_price'] * position['direction'] * position['leverage']
        if pnl_pct < -0.015: return "CLOSE", f"ğŸ›‘ Stop Loss (-1.5%)"
        
        # 2. ìµœì†Œ ë³´ìœ  ì‹œê°„ (ìŠ¤ìº˜í•‘ì´ë¯€ë¡œ 3ë¶„ìœ¼ë¡œ ë‹¨ì¶•)
        import time
        if time.time() - position['entry_time'] < 180: # 3ë¶„
             if pnl_pct > -0.005: # í° ì†ì‹¤ ì•„ë‹ˆë©´ ì¢€ ë” ì§€ì¼œë´„
                 return "HOLD", "â³ Min Hold (3m)"

        # 3. [ìˆ˜ì •] LSMC Horizon ë™ê¸°í™” (15ë¶„ ì˜ˆì¸¡)
        # ê¸°ì¡´: 48ì‹œê°„ -> ìˆ˜ì •: 15ë¶„ (1ë¶„ë´‰ ê¸°ì¤€ 15ê°œ)
        mc_paths = mc_engine.generate_raw_paths(
            symbol=symbol,
            current_price=current_price,
            mu=market_data['predicted_mu'],
            sigma=market_data['volatility'],
            n_steps=15,    # [ë³€ê²½] 15 steps (15ë¶„)
            dt=1/525600,   # [ë³€ê²½] 1ë¶„ ë‹¨ìœ„ (1ë…„=525600ë¶„)
            n_paths=5000
        )
        
        exercise_val, continue_val = self.lsm.calculate_values(
            mc_paths, position['entry_price'], position['direction'], position['leverage']
        )
        
        # íŒê²° ë¡œì§ (Scalpingì— ë§ê²Œ ë¯¼ê°ë„ ì¡°ì ˆ)
        score_close = 0
        
        # ë¯¸ë˜ê°€ì¹˜ë³´ë‹¤ í˜„ì¬ê°€ì¹˜ê°€ ë” í¬ë©´ (ì¦‰, ê³ ì  ì°ê³  ë‚´ë ¤ê°ˆ ê²ƒ ê°™ìœ¼ë©´)
        if exercise_val > continue_val * 1.01: # 1% ë” ë²„ëŠ” ê²ƒë³´ë‹¤ ì§€ê¸ˆ íŒŒëŠ”ê²Œ ë‚«ë‹¤
            score_close += 50
            
        # OU ê³¼ì—´ (Z-Score > 2.5)
        z_score = self.ou.get_z_score(np.array(historical_prices))
        if abs(z_score) > 2.5:
            score_close += 30
            
        if score_close >= 50:
            return "CLOSE", f"ğŸ“‰ Optimal Exit (Val:{exercise_val:.4f} > Fut:{continue_val:.4f})"
            
        return "HOLD", f"ğŸ’ Holding (Upside Left)"